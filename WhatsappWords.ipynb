{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "sns.set(style='white', context='talk')\n",
    "\n",
    "# Use a different font if you want. Symbola supports all emojis\n",
    "matplotlib.rcParams['font.family'] = 'Symbola'\n",
    "\n",
    "# How many words do you wanna compare on the graph?\n",
    "top_word_n = 15\n",
    "\n",
    "# Define color palette here\n",
    "custom_palette = sns.dark_palette('#eb348c', n_colors=top_word_n, reverse=True)\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "# Regex for removing the WhatsApp timestamp\n",
    "regex = re.compile('\\d*\\/\\d*\\/\\d*,\\s\\d*:\\d*\\s[AP][M]\\s-\\s[A-Za-z\\d\\s]*:\\s')\n",
    "# This is the same as the previous except for a capturing group for the name labels in the chat txt file\n",
    "regex_name = re.compile('\\d*\\/\\d*\\/\\d*,\\s\\d*:\\d*\\s[AP][M]\\s-\\s([A-Za-z\\d\\s]*):\\s')\n",
    "\n",
    "out_file = 'messages.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding custom stopwords here\n",
    "stop.extend([\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code looks for a *data.txt* file exported directly from WhatsApp. Open a chat with a contact, go to the menu on the top right (three dots). Expand *More* and click *Export Chat*. You can export it without media since the code only needs the text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some notes:\n",
    "\n",
    "* Replace all new lines in the text file so it is basically uninterrupted text. We can pattern match the timestamps to identify new messages\n",
    "* We can also replace the matched timestamps with a separator of our choice\n",
    "* Multi-line messages in the original chat will be represented in a single-line\n",
    "* We need to iterate through the dataset initially and store the names of the people in the chat so we can label messages later on\n",
    "\n",
    "----\n",
    "\n",
    "* Why parse timestamps into a set/dictionary? Each timestamp is not unique - WhatsApp does mm/dd/yy, hh:mm AM/PM timestamps. Multiple messages possible with same timestamp BUT names might be different\n",
    "* Having a dictionary helps us easily replace the massive exported chat with a simple but time-consuming and inefficient 'replace key with value' operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = 'data.txt'\n",
    "\n",
    "timestamps = {}\n",
    "names = {}\n",
    "tags = {}\n",
    "\n",
    "with open(datafile, 'r') as text:\n",
    "    data = text.read().replace('\\n', '')\n",
    "    matches = re.findall(regex, data)\n",
    "    namelist = set(re.findall(regex_name, data))\n",
    "\n",
    "# Set tags for names to replace and build dataset\n",
    "tag = 1\n",
    "for name in namelist:\n",
    "    names[name] = tag\n",
    "    tag += 1\n",
    "\n",
    "# Set timestamps to be replaced\n",
    "for match in matches:\n",
    "    tag = 0 # tag not found\n",
    "    for name in names:\n",
    "        tag = names[name] if name in match else tag\n",
    "    timestamps[match] = '\\n{}, '.format(str(tag))\n",
    "\n",
    "# Lookup for tag -> name\n",
    "for name, tag in names.items():\n",
    "    tags[tag] = name\n",
    "\n",
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for timestamp in timestamps:\n",
    "    data = data.replace(timestamp, timestamps[timestamp])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up, remove encryption notification at start of chat, remove media messages\n",
    "# Save as CSV\n",
    "messages = pd.DataFrame([[i[:1], i[2:]] for i in data.split('\\n')[1:]])\n",
    "messages.columns = ['tag', 'message']\n",
    "messages = messages[~messages['message'].str.contains('Media omitted')].reset_index(drop=True)\n",
    "\n",
    "messages.to_csv(out_file)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(out_file, index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define names for the tags here\n",
    "tags = {1: '', 2: ''}\n",
    "names = {'': 1, '': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"{} sent {} messages and {} sent {} messages\".format(tags[1], data[data.tag == 1].shape[0],\n",
    "                                                     tags[2], data[data.tag == 2].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_a = data[data.tag == 1]\n",
    "user_b = data[data.tag == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_a['clean_message'] = user_a['message'].apply(lambda x: [word.lower() for word in x.split() if word.lower() not in stop])\n",
    "user_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqs = Counter()\n",
    "for words in user_a['clean_message']:\n",
    "    counts = Counter(words)\n",
    "    word_freqs += counts\n",
    "\n",
    "final_counts = sorted(word_freqs.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_a_counts = final_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = [i[0] for i in user_a_counts[:top_word_n]]\n",
    "top_counts = [i[1] for i in user_a_counts[:top_word_n]]\n",
    "\n",
    "sns.barplot(top_words, top_counts, palette=custom_palette)\n",
    "plt.yticks([], [])\n",
    "plt.xticks(fontsize=10)\n",
    "plt.gcf().subplots_adjust(bottom=0.35)\n",
    "plt.box(False)\n",
    "plt.savefig('output_user_a.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_b['clean_message'] = user_b['message'].apply(lambda x: [word.lower() for word in x.split() if word.lower() not in stop])\n",
    "user_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqs = Counter()\n",
    "for words in user_b['clean_message']:\n",
    "    counts = Counter(words)\n",
    "    word_freqs += counts\n",
    "\n",
    "final_counts = sorted(word_freqs.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_b_counts = final_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = [i[0] for i in user_b_counts[:top_word_n]]\n",
    "top_counts = [i[1] for i in user_b_counts[:top_word_n]]\n",
    "\n",
    "sns.barplot(top_words, top_counts, palette=custom_palette)\n",
    "plt.yticks([], [])\n",
    "plt.xticks(fontsize=10)\n",
    "plt.gcf().subplots_adjust(bottom=0.35)\n",
    "plt.box(False)\n",
    "plt.savefig('output_user_b.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_message'] = data['message'].apply(\n",
    "    lambda x: [word.lower() for word in x.split() if word.lower() not in stop])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqs = Counter()\n",
    "for words in data['clean_message']:\n",
    "    counts = Counter(words)\n",
    "    word_freqs += counts\n",
    "\n",
    "final_counts = sorted(word_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "total_counts = final_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = [i[0] for i in total_counts[:top_word_n]]\n",
    "top_counts = [i[1] for i in total_counts[:top_word_n]]\n",
    "\n",
    "sns.barplot(top_words, top_counts, palette=custom_palette)\n",
    "plt.yticks([], [])\n",
    "plt.xticks(fontsize=10)\n",
    "plt.gcf().subplots_adjust(bottom=0.35)\n",
    "plt.box(False)\n",
    "plt.savefig('output_user_combined.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clean up pre-processing logic and remove the 'replace and reassign' step\n",
    "* DRY - abstract the graph generation into a function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
